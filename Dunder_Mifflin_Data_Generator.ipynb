{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cemsakarya/whitepaper-parkinglot/blob/main/Dunder_Mifflin_Data_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yp4OT30SKbeG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "random.seed(2704)\n",
        "number_of_rows = 10_000\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNt-kkhVWMWh"
      },
      "source": [
        "## Parsing the Wikipedia page for Paper Products and Pennsylvania Counties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UbSHXWk_WMWj"
      },
      "outputs": [],
      "source": [
        "def find_between( s, first, last ):\n",
        "    try:\n",
        "        start = s.index( first ) + len( first )\n",
        "        end = s.index( last, start )\n",
        "        return s[start:end]\n",
        "    except ValueError:\n",
        "        return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WkN-AutPWMWj"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\n",
        "url='https://en.wikipedia.org/wiki/Category:Paper_products',\n",
        ")\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Get all the links\n",
        "allLinks = soup.find(id=\"bodyContent\").find_all(\"a\")\n",
        "random.shuffle(allLinks)\n",
        "linkToScrape = 0\n",
        "\n",
        "list_of_products = []\n",
        "for i in allLinks:\n",
        "    if str(i)[:15] == \"\"\"<a href=\"/wiki/\"\"\":\n",
        "        try:\n",
        "            s = find_between( str(i), \"\"\"href=\"/wiki/\"\"\", \"\"\"\" title=\"\"\" )\n",
        "            if \"category\" in s.lower():\n",
        "                pass\n",
        "            else:\n",
        "                list_of_products += [s]\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J--cWvvgWMWk",
        "outputId": "9949fbcb-601b-4087-ea69-b2c09ff4ccfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Products: 100\n",
            "\n",
            "10 Examples\n",
            "\n",
            "Chinet\n",
            "Anaglypta\n",
            "Holy_card\n",
            "Receipt\n",
            "Ticket_(admission)\n",
            "Softwall\n",
            "Duo-Tang\n",
            "Coffee_cup_sleeve\n",
            "Passbook\n",
            "Container_compression_test\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of Products: {len(list_of_products)}\")\n",
        "print('\\n10 Examples\\n')\n",
        "print(*list_of_products[:10], sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YPa_czLMWMWl"
      },
      "outputs": [],
      "source": [
        "response = requests.get(\n",
        "url='https://en.wikipedia.org/wiki/List_of_counties_in_Pennsylvania',\n",
        ")\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Get all the links\n",
        "allLinks = soup.find(id=\"bodyContent\").find_all(\"a\")\n",
        "random.shuffle(allLinks)\n",
        "linkToScrape = 0\n",
        "\n",
        "list_of_counties = []\n",
        "for i in allLinks:\n",
        "    if str(i)[:15] == \"\"\"<a href=\"/wiki/\"\"\":\n",
        "        try:\n",
        "            s = find_between( str(i), \"\"\"href=\"/wiki/\"\"\", \"\"\"\" title=\"\"\" )\n",
        "            if \"category\" in s.lower():\n",
        "                pass\n",
        "            elif not \"_pennsylvania\" in s.lower():\n",
        "                pass\n",
        "            else:\n",
        "                list_of_counties += [s]\n",
        "        except:\n",
        "            continue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rwa6i8cWMWm"
      },
      "source": [
        "## Datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OcHR-T6XS0xH"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "    \n",
        "def str_time_prop(start, end, time_format, prop):\n",
        "    \"\"\"Get a time at a proportion of a range of two formatted times.\n",
        "\n",
        "    start and end should be strings specifying times formatted in the\n",
        "    given format (strftime-style), giving an interval [start, end].\n",
        "    prop specifies how a proportion of the interval to be taken after\n",
        "    start.  The returned time will be in the specified format.\n",
        "    \"\"\"\n",
        "\n",
        "    stime = time.mktime(time.strptime(start, time_format))\n",
        "    etime = time.mktime(time.strptime(end, time_format))\n",
        "\n",
        "    ptime = stime + prop * (etime - stime)\n",
        "\n",
        "    return time.strftime(time_format, time.localtime(ptime))\n",
        "\n",
        "\n",
        "def random_date(start, end, prop):\n",
        "    return str_time_prop(start, end, '%m/%d/%Y %I:%M %p', prop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zBHYIfagWMWn"
      },
      "outputs": [],
      "source": [
        "list_of_salesman = [\"Dwight Schrute\", \"Jim Halpert\", \"Stanley Hudson\", \"Phyllis Vance\", \"Andrew Bernard\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jv2CY0KEWMWn"
      },
      "outputs": [],
      "source": [
        "list_of_accountants = [\"Kevin Malone\", \"Angela Martin\", \"Oscar Martinez\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1G-U_iQiWMWo"
      },
      "outputs": [],
      "source": [
        "prices_of_products = dict(zip(list_of_products, np.random.randint(10,200,size=(number_of_rows, 1)[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhiiyNNzWMWo"
      },
      "source": [
        "## Customers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mTfoGDxDWMWo"
      },
      "outputs": [],
      "source": [
        "word_site = \"https://www.mit.edu/~ecprice/wordlist.100000\"\n",
        "\n",
        "response = requests.get(word_site)\n",
        "WORDS = response.content.splitlines()\n",
        "\n",
        "def business_name_generator():\n",
        "    word = random.choice(WORDS)\n",
        "    WORDS.remove(word)\n",
        "    return word.decode(\"utf-8\")  + \".inc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3wTCvcfWMWp",
        "outputId": "f281a230-e7ba-4597-de23-d5e6bcee2ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting names\n",
            "  Downloading names-0.3.0.tar.gz (789 kB)\n",
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 25.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 20 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 40 kB 10.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 71 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 92 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 102 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 112 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 122 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 133 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 143 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 153 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 163 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 174 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 184 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 194 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 204 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 215 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 225 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 235 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 245 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 256 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 266 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 276 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 286 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 296 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 307 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 317 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 327 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 337 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 348 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 358 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 368 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 378 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 389 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 399 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 409 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 419 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 430 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 440 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 450 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 460 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 471 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 481 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 491 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 501 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 512 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 522 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 532 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 542 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 552 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 563 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 573 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 583 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 593 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 604 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 614 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 624 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 634 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 645 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 655 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 665 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 675 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 686 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 696 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 706 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 716 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 727 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 737 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 747 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 757 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 768 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 778 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 788 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 789 kB 11.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: names\n",
            "  Building wheel for names (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for names: filename=names-0.3.0-py3-none-any.whl size=803699 sha256=7f61187a6aebbc9f88224b76c9ae529404f17f910b506f6fb37787d1672227aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/ea/68/92f6b0669e478af9b7c3c524520d03050089e034edcc775c2b\n",
            "Successfully built names\n",
            "Installing collected packages: names\n",
            "Successfully installed names-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install names\n",
        "import names\n",
        "\n",
        "def name_generator():\n",
        "    return names.get_full_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WOnRYPTQWMWp"
      },
      "outputs": [],
      "source": [
        "list_of_job_titles = [\"General Manager\",\"Administrative Assistant\",\"Executive Assistant\",\"Marketing Manager\",\n",
        "              \"Customer Service Representative\",\"Nurse Practitioner\",\n",
        "              \"Sales Manager\",\"Data Entry Clerk\",\"Office Assistant\", \"Supply Manager\", \"Supply Manager\", np.nan]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BQ9qyuspWMWp"
      },
      "outputs": [],
      "source": [
        "class _customer:\n",
        "    def __init__(self):\n",
        "        self.name = business_name_generator()\n",
        "        self.customer_id = uuid.uuid4().hex\n",
        "        self.county = random.choice(list_of_counties)\n",
        "        self.Main_Customer_Representative = name_generator()\n",
        "        self.Secondary_Customer_Representative = name_generator()\n",
        "        self.Tertiary_Customer_Representative = name_generator()\n",
        "        self.Main_Customer_Representative_Job_Title  = random.choice(list_of_job_titles)\n",
        "        self.Secondary_Customer_Representative_Job_Title  = random.choice(list_of_job_titles)\n",
        "        self.Tertiary_Customer_Representative_Job_Title   = random.choice(list_of_job_titles)\n",
        "        self.salesman = random.choice(list_of_salesman)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NLnR4QULWMWp"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "customer_df = pd.DataFrame([])\n",
        "while i < 500:\n",
        "    customer = _customer()\n",
        "    temp = pd.DataFrame([[customer.name, customer.customer_id, customer.county, customer.Main_Customer_Representative,\n",
        "                    customer.Secondary_Customer_Representative, customer.Tertiary_Customer_Representative,\n",
        "                    customer.Main_Customer_Representative_Job_Title, customer.Secondary_Customer_Representative_Job_Title,\n",
        "                    customer.Tertiary_Customer_Representative_Job_Title, customer.salesman]])\n",
        "    \n",
        "    customer_df = customer_df.append(temp) \n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M65I-euTWMWq"
      },
      "outputs": [],
      "source": [
        "customer_df.columns = [\"name\", \"customer_id\", \"county\", \"Main_Customer_Representative\",\n",
        "                    \"Secondary_Customer_Representative\", \"Tertiary_Customer_Representative\",\n",
        "                    \"Main_Customer_Representative_Job_Title\", \"Secondary_Customer_Representative_Job_Title\",\n",
        "                    \"Tertiary_Customer_Representative_Job_Title\", \"Salesman\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fy5jR-vWMWq"
      },
      "source": [
        "## Sales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3T3j4whTWMWq"
      },
      "outputs": [],
      "source": [
        "class _sales:\n",
        "    def __init__(self, salesman, customer_representative):\n",
        "        self.sales_id = uuid.uuid4().hex\n",
        "        self.sales_datetime_str = random_date(\"1/1/2008 12:00 PM\", \"1/1/2010 12:00 PM\", random.random())\n",
        "        \n",
        "        self.sales_datetime = datetime.strptime(self.sales_datetime_str, '%m/%d/%Y %I:%M %p')\n",
        "        self.product = random.choice(list_of_products)\n",
        "        self.number_of_units = np.random.randint(100,2000,size=(1, 1))[0][0]\n",
        "        self.price_by_unit = prices_of_products[self.product]\n",
        "        self.salesman = salesman\n",
        "        \n",
        "        self.delivery_how_many_days_later = timedelta(days = int(np.random.randint(1,30,size=(1, 1))[0][0])  )\n",
        "        self.delivery_date = ((self.sales_datetime + self.delivery_how_many_days_later).date()).strftime(\"%m/%d/%Y\")\n",
        "        \n",
        "        self.data_entry_how_many_days_later = timedelta(days = int(np.random.randint(1,10,size=(1, 1))[0][0])  )\n",
        "        self.data_entry_date = ((self.sales_datetime + self.data_entry_how_many_days_later).date()).strftime(\"%m/%d/%Y\")\n",
        "        self.data_entry_officer = random.choice(list_of_accountants)\n",
        "        \n",
        "        self.customer_representative = customer_representative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E2bUy-3bWMWr"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "sales_df = pd.DataFrame([])\n",
        "while i < number_of_rows:\n",
        "    \n",
        "    salesman = random.choice(list_of_salesman)\n",
        "    customer_representative = random.choice(customer_df[customer_df[\"Salesman\"] == salesman][\"Main_Customer_Representative\"].tolist() + customer_df[customer_df[\"Salesman\"] == salesman][\"Secondary_Customer_Representative\"].tolist() + customer_df[customer_df[\"Salesman\"] == salesman][\"Tertiary_Customer_Representative\"].tolist())\n",
        "    \n",
        "    sale = _sales(salesman, customer_representative)\n",
        "    temp = pd.DataFrame([[ sale.sales_id,  sale.sales_datetime_str, sale.sales_datetime, sale.product, \n",
        "                          sale.number_of_units, sale.price_by_unit, \n",
        "                            sale.salesman, sale.delivery_how_many_days_later,\n",
        "                            sale.delivery_date, sale.data_entry_how_many_days_later, sale.data_entry_date, \n",
        "                          sale.data_entry_officer, sale.customer_representative]])\n",
        "    \n",
        "    sales_df = sales_df.append(temp) \n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ykyduIB-WMWr"
      },
      "outputs": [],
      "source": [
        "sales_df.columns = [\"Order ID\",\"Order Entry Datetime Str\",\"Order Entry Datetime\",\"Product\",\"# of Units\",\n",
        "                    \"Price by Unit\",\"Salesman\",\n",
        "                          \"Delivery How Many Dates Later\", \"Delivery Date\", \n",
        "                    \"Data Entry How Many Dates Later\",\n",
        "                    \"Data Entry Date\", \"Data Entry Officer\", \"Customer Representative\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvYuSkSdWMWr"
      },
      "source": [
        "## Warehouse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AMlYDA-UWMWr"
      },
      "outputs": [],
      "source": [
        "class _warehouse:\n",
        "    def __init__(self, order_id, order_date, latency_customer):\n",
        "        self.order_id = order_id\n",
        "        self.order_date = datetime.strptime(order_date, '%m/%d/%Y %I:%M %p')\n",
        "        self.latency_customer = latency_customer\n",
        "        self.quality_control = None   \n",
        "        \n",
        "        self.latency_load = timedelta(days = int(np.random.randint(0,5,size=(1, 1))[0][0]))      \n",
        "        \n",
        "        self.load_date = ((self.order_date + self.latency_customer + self.latency_load).date()).strftime(\"%m/%d/%Y\")       \n",
        "        \n",
        "        self.latency_delivery = timedelta(days = int(np.random.randint(0,5,size=(1, 1))[0][0])) \n",
        "        \n",
        "        \n",
        "        self.delivery_date = ((self.order_date + self.latency_customer + self.latency_load + self.latency_delivery).date()).strftime(\"%m/%d/%Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uW4-Y2BYWMWr"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "warehouse_logs = pd.DataFrame([])\n",
        "for index, row in sales_df.iterrows():\n",
        "    log = _warehouse(row[\"Order ID\"], row[\"Order Entry Datetime Str\"], row[\"Delivery How Many Dates Later\"])\n",
        "    \n",
        "    temp = pd.DataFrame([[ log.order_id, log.order_date, log.latency_customer, log.quality_control,\n",
        "                         log.latency_load, log.load_date, log.latency_delivery, log.delivery_date]])\n",
        "    \n",
        "    warehouse_logs = warehouse_logs.append(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP9ATKk0WMWs"
      },
      "outputs": [],
      "source": [
        "warehouse_logs.columns = [\"Order ID\", \n",
        "                          \"Order Date\",\n",
        "                          \"Latency Customer\",\n",
        "                          \"Quality Control Check is Done\",\n",
        "                          \"Latency Load\",\n",
        "                          \"Load Date\",\n",
        "                          \"Latency Delivery\",\n",
        "                          \"Delivery Date\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8f5a9FOWMWs"
      },
      "outputs": [],
      "source": [
        "sales_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7XrjzPmWMWs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfndtqBTWMWs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CaGy1MRCWMWs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Dunder_Mifflin_Data_Generator.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}